{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c112706f-27e9-4829-97ff-67287373edeb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3248c855-ee3b-4122-85e6-e6ee0fcc96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c45663-082b-413b-bd5d-edac94ac6112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfdaff24-b120-4b09-92af-ec360c19cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.models.whisper import WhisperTokenizerFast, WhisperFeatureExtractor, WhisperForConditionalGeneration\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial\n",
    "from dataloader.preprocessing_train.preprocessing import prepare_dataset_fct\n",
    "from evaluation.eval_dataset_name_to_dataset_group import EVAL_DATASET_NAME_TO_DATASET_GROUP\n",
    "\n",
    "device = torch.device('cpu')\n",
    "sns.set_theme(context=\"paper\", style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8aff0-e85e-4244-9fb4-8ef192846b20",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0ce848-466c-4d09-8047-1baf5f9a313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name_or_path = \"openai/whisper-tiny\"\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(pretrained_model_name_or_path).to(device)\n",
    "model.generation_config.alignment_heads = [[2, 2], [3, 0], [3, 2], [3, 3], [3, 4], [3, 5]]\n",
    "\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(pretrained_model_name_or_path, language=\"english\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(pretrained_model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f362c-aabd-4c7f-a189-ea6c3e0b13be",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b08bf1a-d042-4e68-beb5-fae128b25e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: `CACHE_DIR_AMI` environment variable not set. Using default cache directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ami (/Users/Tony/.cache/huggingface/datasets/edinburghcstr___ami/ihm/0.0.0/0d128d0aa8145d0f16f3d5b4da86c5d5759dbe9e8f947fda04b25edb56442bd5)\n",
      "Found cached dataset ami (/Users/Tony/.cache/huggingface/datasets/edinburghcstr___ami/ihm/0.0.0/0d128d0aa8145d0f16f3d5b4da86c5d5759dbe9e8f947fda04b25edb56442bd5)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"ami_validation\"\n",
    "\n",
    "ds = EVAL_DATASET_NAME_TO_DATASET_GROUP[\"ami_eval\"]()[\"ami_validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322f016a-3a1c-4f39-bef5-a00c153e93eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.select(list(range(8)))\n",
    "prepare_dataset = partial(prepare_dataset_fct, tokenizer=tokenizer, feature_extractor=feature_extractor)\n",
    "ds = ds.map(prepare_dataset, num_proc=4).with_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e06a372-563e-47f2-9c4d-b9ba8ea5d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlmi-dissertation-new/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "odict_keys(['sequences', 'encoder_attentions', 'decoder_attentions', 'cross_attentions', 'token_timestamps'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids = model.generate(ds[\"input_features\"], return_token_timestamps=True)\n",
    "\n",
    "predicted_ids.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce44d39e-a1de-49ad-8ca9-cb97a1d1e1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363,   583,   411,  6013, 10216,   362, 11171,\n",
       "           293,   436,   434,  7084,    13, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257],\n",
       "        [50258, 50259, 50359, 50363,   291, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257],\n",
       "        [50258, 50259, 50359, 50363,  4919,    13, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids[\"sequences\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfef2b76-dbcb-4a65-90be-96efa035f1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2800,  0.4200,  0.7600,\n",
       "          1.0600,  1.4200,  1.8000,  2.2000,  2.2800,  2.2800,  2.6600,  5.2800,\n",
       "         23.0800, 23.0800, 23.0800, 23.0800, 23.0800, 23.1000, 23.1400],\n",
       "        [ 0.0000,  0.0000, 29.6200, 29.6200, 29.6200, 29.6200, 29.6200, 29.6400,\n",
       "         29.6600, 29.6600, 29.6600, 29.6600, 29.6600, 29.6600, 29.6600, 29.6600,\n",
       "         29.6600, 29.6600, 29.6600, 29.7800, 29.7800, 29.7800, 29.7800],\n",
       "        [ 0.0000,  0.0000, 11.6000, 29.6400, 29.6400, 29.6400, 29.6400, 29.6400,\n",
       "         29.6400, 29.6600, 29.6600, 29.6600, 29.6600, 29.6600, 29.7800, 29.7800,\n",
       "         29.7800, 29.7800, 29.7800, 29.7800, 29.7800, 29.7800, 29.7800]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids[\"token_timestamps\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f53602-7e69-46e4-8fc7-d3b60709419c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
