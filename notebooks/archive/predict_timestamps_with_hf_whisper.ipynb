{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b9057d-d162-4f59-800d-191a095adf6b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633464c0-61c5-40da-ae71-602c1a73f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245231f7-06ff-42e8-8874-70f61cbecadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71dff081-2791-45a5-9c84-945e987183b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.models.whisper import (WhisperTokenizer,\n",
    "                                         WhisperTokenizerFast,\n",
    "                                         WhisperFeatureExtractor,\n",
    "                                         WhisperForConditionalGeneration)\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dataloader.dataset_loader import gen_from_dataset\n",
    "from evaluation.eval_dataset_name_to_dataset_group import EVAL_DATASET_NAME_TO_DATASET_GROUP\n",
    "from evaluation.string_edit_metrics import get_string_edit_metrics\n",
    "\n",
    "from utils.constants import GEN_MAX_LENGTH, DEFAULT_EVAL_NUM_BEAMS\n",
    "\n",
    "device = torch.device('mps')\n",
    "sns.set_theme(context=\"paper\", style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3e11e-9a34-4c24-8b77-21aa225047e6",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b0c61-846c-40cc-a729-15b716a3df96",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9ed856-8cf0-42f5-a80a-9c9856871d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name_or_path = \"openai/whisper-tiny\"\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(pretrained_model_name_or_path).to(device)\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(pretrained_model_name_or_path)\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(pretrained_model_name_or_path,\n",
    "                                                 language=\"english\",\n",
    "                                                 task=\"transcribe\",\n",
    "                                                 predict_timestamps=True)\n",
    "\n",
    "whisper_norm = tokenizer._normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b0b65-0fd2-415c-892f-602e671b9e89",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2808bc4b-c8c2-404b-bd97-f7da9d0ab978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: `CACHE_DIR_LIBRISPEECH` environment variable not set. Using default cache directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94fb7cd56844d1db84c5a6c7aa7725f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset librispeech_asr_dummy/clean to /Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9102c5c502b4546bcb2c67afa58b205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0373a352827f4676a05d6c08bba575d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015cfa8ff6d040d892e5d2fb7e0629bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset librispeech_asr_dummy downloaded and prepared to /Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = \"librispeech_dummy\"\n",
    "\n",
    "ds_group = EVAL_DATASET_NAME_TO_DATASET_GROUP[dataset_name]()\n",
    "\n",
    "if dataset_name == \"librispeech_dummy\":\n",
    "    ds = ds_group.str2dataset[\"librispeech_dummy\"]\n",
    "    ds = ds.map(lambda x: {\"text\": x.lower()}, input_columns=[\"text\"])\n",
    "elif dataset_name in [\"ami\", \"ami_10h\"]:\n",
    "    ds = ds_group.str2dataset[\"ami\"]\n",
    "    ds = ds.map(lambda x: {\"text\": x.lower()}, input_columns=[\"text\"])\n",
    "else:\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5cc43f4-5b64-4be2-90d9-c507910af2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ds[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dafc2ae4-db2a-4469-a965-7551a4388e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "670c49d0-734d-4c34-99e8-d5f111b5795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ids = model.generate(input_features.to(device), return_timestamps=True, task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cde3cfed-41bd-4b8e-b507-99d7a54274a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|en|><|transcribe|><|0.00|> Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.<|5.44|><|endoftext|>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generate_ids[0], decode_with_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226b530-70a7-4448-88e1-1932f282bcee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
