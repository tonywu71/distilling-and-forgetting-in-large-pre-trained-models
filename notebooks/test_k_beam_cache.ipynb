{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27867109-c7a5-44fe-9d0b-834d23cf0c5f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe3b852e-1d8a-48f1-a28e-6d70058a2cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ddf840-c71f-4493-a4aa-89163e1fe918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tw581/mlmi_dissertation/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc5bec0-89e2-4e20-949e-a641a559d7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.initialize import initialize_env, print_envs\n",
    "initialize_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "484748ac-06a2-411d-b5e8-bc9a5ad4456c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available(), \"This script requires a GPU.\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dataloader.smart_load_dataset_dict import smart_load_dataset_dict\n",
    "from utils.distil_config import DistilConfig\n",
    "from utils.constants import GEN_MAX_LENGTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786ffe80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilConfig(experiment_name='distil_whisper_base_to_tiny-seq_level_k_best_uniform-k_3-debug', lang_name='english', task='transcribe', method='seq_level_k_best_uniform', teacher_model_name_or_path='openai/whisper-base', student_model_name_or_path='openai/whisper-tiny', is_tokenizer_multilingual=True, model_dir='./checkpoints/distillation/whisper_base_to_tiny/librispeech_debug/seq_level_k_best_uniform/k_3/', freeze_encoder=True, freeze_decoder=False, batch_size=16, gradient_accumulation_steps=4, eval_accumulation_steps=None, gradient_checkpointing=True, data_augmentation=False, dataset_name='librispeech_dummy', force_reprocess_dataset=False, optim='adamw_torch', learning_rate=1e-05, warmup_steps=5, eval_steps=5, generation_num_beams=3, save_steps=100, save_total_limit=2, logging_steps=5, num_train_epochs=10, early_stopping_patience=-1, ce_alpha=0.5, temperature=None, distillation_num_beams=3, decay_beta=1.0, smart_load=True, force_reprocess_k_best=False, log_preds_to_wandb=True, n_samples_per_wandb_logging_step=8, log_raw_str=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = DistilConfig.from_yaml(\"configs/distill_configs/seq_level_k_best_uniform/distil_base_to_tiny-seq_level_k_best_uniform-k_3-debug.yaml\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "691aecf9-ee66-497a-9f2b-28413b00dd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "normalizer = processor.tokenizer._normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9030b3d8-9f30-4370-a7a1-b72790545d78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load processor (contains both tokenizer and feature extractor)\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    config.teacher_model_name_or_path,\n",
    "    language=config.lang_name,\n",
    "    task=config.task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28bf600e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously preprocessed dataset found at `/home/tw581/rds/hpc-work/preprocessed_datasets/librispeech_dummy/multilingual_tokenizer`. Loading from disk...\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = smart_load_dataset_dict(config=config, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a177da1-1aa9-461b-a154-cb3cface5f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id', 'input_features', 'labels'],\n",
       "        num_rows: 72\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id', 'input_features', 'labels'],\n",
       "        num_rows: 73\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id', 'input_features', 'labels'],\n",
       "        num_rows: 73\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e1ad7-bc2e-4ef2-a2b9-e77a11380d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940c145-178c-44fd-9b66-9a137991ea4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdbcbc-9d63-4ccf-9125-acec9bc1cec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f92d77-7f60-427f-a024-b213dd00396e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f15198e3-f017-4307-8ccb-30a3e50defbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_beams = 3\n",
    "\n",
    "\n",
    "def get_k_beam_features(batch: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Utility to create K-Beam features for a dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # Note that we need to move the data to the device manually (which is not the case with Trainer):\n",
    "    # input_features = data[\"input_features\"].to(device)  # type: ignore\n",
    "    input_features = batch[\"input_features\"]\n",
    "\n",
    "    # Generate teacher predictions using K-beam search:\n",
    "    outputs = model.generate(input_features,  # type: ignore\n",
    "                             max_length=GEN_MAX_LENGTH,\n",
    "                             num_beams=num_beams,\n",
    "                             num_return_sequences=num_beams,\n",
    "                             output_scores=True,\n",
    "                             return_dict_in_generate=True)\n",
    "    \n",
    "    # outputs.sequences -> (batch_size * num_beams, n_tokens)\n",
    "    # outputs.sequences_scores -> (batch_size * num_beams,)\n",
    "    \n",
    "    batch[\"sequences\"] = list(torch.split(outputs.sequences,\n",
    "                                     split_size_or_sections=num_beams,\n",
    "                                     dim=0))\n",
    "    batch[\"sequences_scores\"] = list(torch.split(outputs.sequences_scores,\n",
    "                                            split_size_or_sections=num_beams,\n",
    "                                            dim=0))\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ca39df1-6dcb-4067-9e22-d4ee5fbdb222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test = dataset_dict.with_format(\"pt\")[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38384d45-1d64-4118-ba2f-401dcd121f64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': Value(dtype='string', id=None),\n",
       " 'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'speaker_id': Value(dtype='int64', id=None),\n",
       " 'chapter_id': Value(dtype='int64', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'input_features': Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bd25f08-0940-4e88-8338-8a369957c874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_test_ = ds_test.map(get_k_beam_features, batched=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8300ef7-520d-4809-8df6-11f074d1f08d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': Value(dtype='string', id=None),\n",
       " 'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'speaker_id': Value(dtype='int64', id=None),\n",
       " 'chapter_id': Value(dtype='int64', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'input_features': Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'sequences': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'sequences_scores': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test_.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28c44135-e0cf-43bb-a8f9-4f5a5f495955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50257, 50362,  1770,    13,  2264,   346,   353,   318,   262, 46329,\n",
       "           286,   262,  3504,  6097,    11,   290,   356,   389,  9675,   284,\n",
       "          7062,   465, 21443,    13, 50256],\n",
       "        [50257, 50362,  1770,    13,  2264,   346,   353,   318,   262, 46329,\n",
       "           286,   262,  3504,  6097,   290,   356,   389,  9675,   284,  7062,\n",
       "           465, 21443,    13, 50256, 50256],\n",
       "        [50257, 50362,  1770,    13,  2264,   346,   353,   318,   262, 46329,\n",
       "           286,   262,  3504,  6097,    11,   290,   356,   389,  9675,   284,\n",
       "          7062,   465, 23244,    13, 50256]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test_[\"sequences\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea3dc3a7-5af8-410b-870f-81941833d0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1096, -0.1257, -0.1332])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test_[\"sequences_scores\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54cb2d-4573-4a42-a9c3-2f9ff15cbf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc64100-34dd-47f8-b43b-cb6cbca7707e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf5690-0e2c-4db4-a31c-eefd66bceb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d31113-b913-4b65-b165-76b8bbbf2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batched_k_beam_search_output_from_inputs(inputs,\n",
    "                                                 col_id: str,\n",
    "                                                 distillation_num_beams: int,\n",
    "                                                 id_to_k_beam_search_output: Dict[str, BeamSearchEncoderDecoderOutput]) -> BeamSearchEncoderDecoderOutput:\n",
    "    \"\"\"\n",
    "    This function is used to get the K-Beam search output for a batch of inputs using the pre-computed K-beam results\n",
    "    in `id_to_k_beam_search_output`. The returned object should be strictly identical to the output of `generate`\n",
    "    on the batched `inputs` tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size, n_tokens = inputs.shape  # n_tokens is such that 1 <= n_tokens <= GEN_MAX_LENGTH\n",
    "    beam_search_size = id_to_k_beam_search_output[col_id].sequences.shape[0]\n",
    "    \n",
    "    # Sanity checks:\n",
    "    assert col_id in inputs.features, f\"Column `{col_id}` not found in inputs.\"\n",
    "    assert distillation_num_beams <= beam_search_size, \\\n",
    "        f\"Invalid `distillation_num_beams` value `{distillation_num_beams}`. Must be <= `{beam_search_size}`.\"\n",
    "    \n",
    "    \n",
    "    # Initialize the output tensors:\n",
    "    sequences = torch.zeros((batch_size * distillation_num_beams, n_tokens), dtype=torch.long, device=device)  # (batch_size * distillation_num_beams, n_tokens)\n",
    "    sequences_scores = torch.zeros((batch_size * distillation_num_beams,), dtype=torch.float, device=device)  # (batch_size * distillation_num_beams,)\n",
    "    \n",
    "    # Loop over the batch:\n",
    "    for idx, sample in enumerate(inputs):\n",
    "        # Get the inputs for the current sample:\n",
    "        sample_id = sample[col_id]  # TODO: str or int???\n",
    "        \n",
    "        # Get the K-beam search output for the current sample:\n",
    "        k_beam_search_output = id_to_k_beam_search_output[sample_id]\n",
    "        \n",
    "        # Get the sequence and its score:\n",
    "        sequence = k_beam_search_output.sequences  # (beam_search_size, n_tokens)\n",
    "        sequence_scores = k_beam_search_output.sequences_scores  # (beam_search_size,)\n",
    "        \n",
    "        # Store the sequence and its score in their respective tensors:\n",
    "        sequences[idx:idx+distillation_num_beams, :len(sequence)] = sequence[:distillation_num_beams, :]\n",
    "        sequences_scores[idx:idx+distillation_num_beams] = sequence_scores[:distillation_num_beams]  # type: ignore\n",
    "    \n",
    "    return BeamSearchEncoderDecoderOutput(sequences=sequences, sequences_scores=sequences_scores)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290661d-0bbe-4b6f-bdf5-a5450bd50455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd838b6-c730-45c1-81db-65a2bd02d34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80daf696-5cbd-40b5-b33a-9887c657abd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
