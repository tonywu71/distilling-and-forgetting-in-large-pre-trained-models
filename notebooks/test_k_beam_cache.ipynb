{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27867109-c7a5-44fe-9d0b-834d23cf0c5f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b852e-1d8a-48f1-a28e-6d70058a2cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ddf840-c71f-4493-a4aa-89163e1fe918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "484748ac-06a2-411d-b5e8-bc9a5ad4456c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dataloader.smart_load_dataset_dict import smart_load_dataset_dict\n",
    "from utils.distil_config import DistilConfig\n",
    "from utils.constants import GEN_MAX_LENGTH, DEFAULT_LABEL_STR_COL, DEFAULT_LABEL_TOKENIZED_COL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2107e437-090c-4409-b276-15b5cfa1e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef612e-e56a-41f1-a328-344d78c493d0",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786ffe80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilConfig(experiment_name='distil_whisper_base_to_tiny-seq_level_k_best_uniform-k_3-debug',\n",
      "             lang_name='english',\n",
      "             task='transcribe',\n",
      "             method_distil='seq_level_k_best_uniform',\n",
      "             teacher_model_name_or_path='openai/whisper-base',\n",
      "             student_model_name_or_path='openai/whisper-tiny',\n",
      "             is_tokenizer_multilingual=True,\n",
      "             model_dir='./checkpoints/distillation/whisper_base_to_tiny/librispeech_debug/seq_level_k_best_uniform/k_3/',\n",
      "             freeze_encoder=True,\n",
      "             freeze_decoder=False,\n",
      "             batch_size=32,\n",
      "             gradient_accumulation_steps=1,\n",
      "             gradient_checkpointing=True,\n",
      "             dataset_name='librispeech_dummy',\n",
      "             optim='adamw_torch',\n",
      "             learning_rate=1e-05,\n",
      "             warmup_steps=5,\n",
      "             eval_steps=10,\n",
      "             generation_num_beams=1,\n",
      "             save_steps=10000,\n",
      "             logging_steps=10,\n",
      "             num_train_epochs=10,\n",
      "             data_augmentation=False,\n",
      "             lowercase=True,\n",
      "             zero_shot_eval=False,\n",
      "             eval_batch_size=32,\n",
      "             eval_accumulation_steps=None,\n",
      "             save_total_limit=2,\n",
      "             early_stopping_patience=-1,\n",
      "             save_final_model=True,\n",
      "             alpha_ce=0.5,\n",
      "             temperature=2,\n",
      "             distillation_num_beams=3,\n",
      "             beta_decay=2.0,\n",
      "             is_hpt=False,\n",
      "             smart_load=True,\n",
      "             force_reprocess_dataset=False,\n",
      "             force_reprocess_k_best=False,\n",
      "             eval_first_step=False,\n",
      "             log_preds_to_wandb=True,\n",
      "             log_raw_str=True,\n",
      "             n_samples_per_wandb_logging_step=8)\n"
     ]
    }
   ],
   "source": [
    "config = DistilConfig.from_yaml(\"configs/distil_configs/debug/distil_base_to_tiny-seq_level_k_best_uniform-k_3-debug.yaml\")\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "691aecf9-ee66-497a-9f2b-28413b00dd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model:\n",
    "model = WhisperForConditionalGeneration.from_pretrained(config.student_model_name_or_path).to(device)\n",
    "\n",
    "# Load processor (contains both tokenizer and feature extractor):\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    config.student_model_name_or_path,\n",
    "    language=config.lang_name,\n",
    "    task=config.task\n",
    ")\n",
    "normalizer = processor.tokenizer._normalize\n",
    "\n",
    "# Disable zero-shot:\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=config.lang_name, task=config.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc06ba1e-df46-49cd-afb6-5d4cf476c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset:\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f15198e3-f017-4307-8ccb-30a3e50defbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_beams = 2\n",
    "\n",
    "def get_k_beam_features(batch: Dict[str, Any], processor) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Utility to create K-Beam features for a dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # ===== Code from prepare_dataset_fct ====\n",
    "    \n",
    "    audio = batch[\"audio\"]\n",
    "    \n",
    "    # Extract features from audio (including log-Mel input features):\n",
    "    # Note: the sampling rate arg is redundant but required to dismiss warnings.\n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"],\n",
    "                                                          sampling_rate=processor.feature_extractor.sampling_rate,\n",
    "                                                          return_tensors=\"pt\").input_features\n",
    "    \n",
    "    # Encode from target text to label ids:\n",
    "    batch[DEFAULT_LABEL_TOKENIZED_COL] = processor.tokenizer(batch[DEFAULT_LABEL_STR_COL]).input_ids  # type: ignore\n",
    "    \n",
    "    # =========================================\n",
    "    \n",
    "    # Note that we need to move the data to the device manually (which is not the case with Trainer):\n",
    "    # input_features = data[\"input_features\"].to(device)  # type: ignore\n",
    "    input_features = batch[\"input_features\"]\n",
    "    \n",
    "    # Generate teacher predictions using K-beam search:\n",
    "    outputs = model.generate(input_features.to(device),  # type: ignore\n",
    "                             max_length=GEN_MAX_LENGTH,\n",
    "                             num_beams=num_beams,\n",
    "                             num_return_sequences=num_beams,\n",
    "                             output_scores=True,\n",
    "                             return_dict_in_generate=True)\n",
    "    \n",
    "    # outputs.sequences -> (batch_size * num_beams, n_tokens)\n",
    "    # outputs.sequences_scores -> (batch_size * num_beams,)\n",
    "    \n",
    "    batch[\"sequences\"] = list(torch.split(outputs.sequences,\n",
    "                                     split_size_or_sections=num_beams,\n",
    "                                     dim=0))\n",
    "    batch[\"sequences_scores\"] = list(torch.split(outputs.sequences_scores,\n",
    "                                            split_size_or_sections=num_beams,\n",
    "                                            dim=0))\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bd25f08-0940-4e88-8338-8a369957c874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlmi-dissertation/lib/python3.10/site-packages/transformers/generation/utils.py:723: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  input_ids = input_ids.repeat_interleave(expand_size, dim=0)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlmi-dissertation/lib/python3.10/site-packages/transformers/generation/beam_search.py:357: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  sent_lengths_max = sent_lengths.max().item() + 1\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(partial(get_k_beam_features, processor=processor), num_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8300ef7-520d-4809-8df6-11f074d1f08d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': Value(dtype='string', id=None),\n",
       " 'audio': Audio(sampling_rate=16000, mono=True, decode=True, id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'speaker_id': Value(dtype='int64', id=None),\n",
       " 'chapter_id': Value(dtype='int64', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'input_features': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'sequences': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'sequences_scores': Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80daf696-5cbd-40b5-b33a-9887c657abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fc2e358-8e0e-4476-b60e-a6f3ef902064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id', 'input_features', 'labels', 'sequences', 'sequences_scores'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f09a077-467c-40bd-983c-613d46dfc9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363,  2221,    13,  2326,   388,   391,   307,\n",
       "           264, 50244,   295,   264,  2808,  5359,   293,   321,   366,  5404,\n",
       "           281,  2928,   702, 14943,    13, 50257, 50257],\n",
       "        [50258, 50259, 50359, 50363,  2221,    13,  2326,   388,   391,   307,\n",
       "           264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "          5404,   281,  2928,   702, 14943,    13, 50257]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_seq = torch.LongTensor(x[\"sequences\"][0])\n",
    "tokenized_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bddddc5d-58c3-4485-86c3-01ed4ccee25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.<|endoftext|><|endoftext|>',\n",
       " '<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.<|endoftext|>']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.batch_decode(tokenized_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aead7072-3408-4724-988e-2ad2b3fb98bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [50258, 50259, 50359, 50363, 44, 2343, 5568, 7246, 4620, 5568, 6205, 5663, 5372, 28067, 2634, 11944, 5663, 32394, 35, 2634, 12855, 19678, 2358, 8093, 15813, 22515, 16225, 6112, 8232, 343, 3158, 34, 23344, 45470, 460, 4367, 47, 3158, 50257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer(x[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd2716-ab65-48a5-8b5e-dd1e8dfa1ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
