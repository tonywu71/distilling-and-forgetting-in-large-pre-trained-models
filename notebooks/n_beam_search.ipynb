{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e5ed54-59fc-48bb-a8f8-cb776ae661ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "# load dummy dataset and read audio files\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "sample = ds[0][\"audio\"]\n",
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e26093-ffe1-4f82-90ee-f90c4d97ac39",
   "metadata": {},
   "source": [
    "## Vanilla N-beam search with `generate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff13017-15d8-47de-a89c-e85b1a4f860d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50257, 50362,  1770,    13,  2264,   346,   353,   318,   262, 46329,\n",
       "            286,   262,  3504,  6097,    11,   290,   356,   389,  9675,   284,\n",
       "           7062,   465, 21443,    13, 50256]]),\n",
       " [' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features, num_beams=3)\n",
    "# decode token ids to text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "predicted_ids, transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbcd1dd-4b38-457d-a88d-9c311c8a238c",
   "metadata": {},
   "source": [
    "## Get top-N sequences from beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68346146-44a2-48a1-a3f9-08f771df2f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50257, 50362,  1770,    13,  2264,   346,   353,   318,   262, 46329,\n",
       "            286,   262,  3504,  6097,    11,   290,   356,   389,  9675,   284,\n",
       "           7062,   465, 21443,    13, 50256],\n",
       "         [50257, 50362,  1770,    13,  2264,   346,   353,   318,   262, 46329,\n",
       "            286,   262,  3504,  6097,   290,   356,   389,  9675,   284,  7062,\n",
       "            465, 21443,    13, 50256, 50256],\n",
       "         [50257, 50362,  1770,    13,  2264,   346,   353,   318,   262, 46329,\n",
       "            286,   262,  3504,  6097,    11,   290,   356,   389,  9675,   284,\n",
       "           7062,   465, 23244,    13, 50256]]),\n",
       " [' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.',\n",
       "  ' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.',\n",
       "  ' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his Gospel.'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features, num_beams=3, num_return_sequences=3)\n",
    "# decode token ids to text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "predicted_ids, transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585f2b8-06d4-4d83-92ff-035efe665530",
   "metadata": {},
   "source": [
    "## Retrieve scores from `generate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e651b799-6c30-4093-a95b-4177c032622a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['sequences', 'sequences_scores', 'scores', 'beam_indices'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(input_features, num_beams=3, output_scores=True, return_dict_in_generate=True)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f19d9b81-b557-408f-8166-c174ba5b0687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50257, 50362,  1770,    13,  2264,   346,   353,   318,   262, 46329,\n",
       "            286,   262,  3504,  6097,    11,   290,   356,   389,  9675,   284,\n",
       "           7062,   465, 21443,    13, 50256]]),\n",
       " tensor([-0.1096]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.sequences, outputs.sequences_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb48087e-cb90-4fea-89bd-8db31656b05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " tensor([[-11.7886,     -inf,     -inf,  ..., -15.2796, -16.0519, -18.6459],\n",
       "         [-11.7886,     -inf,     -inf,  ..., -15.2796, -16.0519, -18.6459],\n",
       "         [-11.7886,     -inf,     -inf,  ..., -15.2796, -16.0519, -18.6459]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns all scores for all N-beams:\n",
    "len(outputs), outputs.scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "582f92a9-ad59-4220-bd5e-7c69426db3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    -inf, -11.7038, -13.6538, -11.9018, -15.5696, -15.5865, -15.5451,\n",
       "          -9.8790, -11.2768, -16.8047,  -9.5083, -10.5973, -16.2507, -17.7821,\n",
       "         -11.9694, -12.2877,  -9.6139, -15.9645, -15.0510, -11.4573, -13.6452,\n",
       "         -15.4599, -15.6448, -12.2026,  -4.7137],\n",
       "        [    -inf, -11.7038, -11.4163, -19.3818, -16.5448, -16.7483, -15.1039,\n",
       "          -9.5228, -11.3053, -17.6024,  -9.5014, -10.5143, -13.7391, -17.9175,\n",
       "          -7.8405, -13.8592, -12.2392, -13.2750, -17.6305,  -9.5785, -17.5459,\n",
       "         -13.4226, -17.2916, -12.1076,  -0.4173],\n",
       "        [    -inf, -11.7038, -11.3371, -18.9002, -10.6250,  -2.9960, -16.9284,\n",
       "          -9.8154, -11.2018, -16.4499,  -9.4196, -10.7639, -13.8377, -17.9994,\n",
       "         -11.9418, -12.3365, -12.6365, -15.1623, -15.3699, -11.4702, -13.8234,\n",
       "         -15.5515, -16.2069, -10.6529,  -4.6477]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get only the scores of the words of interest, use the following:\n",
    "transition_scores = model.compute_transition_scores(\n",
    "    outputs.sequences, outputs.scores, normalize_logits=True\n",
    ")\n",
    "\n",
    "transition_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72655c3-6957-4933-b142-d555e2082bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
