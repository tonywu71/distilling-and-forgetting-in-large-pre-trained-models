{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37324580-06a0-4be8-8194-70b8f85523c3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb50902-acec-4fe8-9681-d944478c0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba60d42-4585-4578-b142-c703099bd091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b422c568-7362-4361-8052-1b78696a1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.models.whisper import (WhisperTokenizer,\n",
    "                                         WhisperTokenizerFast,\n",
    "                                         WhisperFeatureExtractor,\n",
    "                                         WhisperForConditionalGeneration)\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "from dataloader.dataset_loader import gen_from_dataset\n",
    "from dataloader.dataset_for_evaluation.librispeech_dummy_dataset import LibriSpeechDummyDataset\n",
    "from evaluation.string_edit_metrics import get_string_edit_metrics\n",
    "\n",
    "device = torch.device('mps')\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fcde89-6579-4200-bb8c-f0d0f618971a",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb40d39-119f-4c6a-b960-99dc206d6350",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44a8a39-776d-4177-ae70-33d876edefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name_or_path = \"openai/whisper-tiny\"\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(pretrained_model_name_or_path)\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(pretrained_model_name_or_path)\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(pretrained_model_name_or_path, language=\"english\", task=\"transcribe\")\n",
    "\n",
    "\n",
    "model.config.forced_decoder_ids = tokenizer.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")  # type: ignore\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "whisper_norm = tokenizer._normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482c627-cd0a-41ba-8e61-96bb22b02956",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2bcf1c7-5715-4c7e-8537-4dd0c06233e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: `CACHE_DIR_LIBRISPEECH` environment variable not set. Using default cache directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "ds_group = LibriSpeechDummyDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af0dc52-2982-4376-ba18-6baf48666b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id'],\n",
       "    num_rows: 73\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds_group.str2dataset[\"librispeech_dummy\"]\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514824b-98c9-407e-a4ff-e800c3aaba75",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ed08a2-7488-4eda-858e-b72410c214ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_asr = pipeline(task=\"automatic-speech-recognition\",\n",
    "                       model=model,\n",
    "                       tokenizer=tokenizer,\n",
    "                       feature_extractor=feature_extractor,  # type: ignore\n",
    "                       device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157d5ba-883a-4ed9-9384-695eaeda6ecb",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e13c4788-c27f-47ee-9acc-3d65d519fd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d852219ade42859f430999380643f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlmi-dissertation/lib/python3.10/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlmi-dissertation/lib/python3.10/site-packages/transformers/generation/utils.py:2396: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  if unfinished_sequences.max() == 0:\n"
     ]
    }
   ],
   "source": [
    "# Create placeholders for the predictions and references:\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for out in tqdm(whisper_asr(gen_from_dataset(ds),\n",
    "                            batch_size=16,\n",
    "                            generate_kwargs={\"num_beams\": 1}),\n",
    "                total=ds.num_rows):\n",
    "    \n",
    "    ref = out[\"reference\"][0]\n",
    "    pred = out[\"text\"]\n",
    "\n",
    "    if not ref.strip():\n",
    "        continue  # skip empty references to avoid error in WER computation\n",
    "\n",
    "    predictions.append(pred)\n",
    "    references.append(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3ab6f-d53d-4409-8065-2258b7d56ca9",
   "metadata": {},
   "source": [
    "## Compute string edit metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39a8f3-4d75-4562-9be1-f3217877938e",
   "metadata": {},
   "source": [
    "Let's try different norm and WER functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675fefc9-2b87-41fb-8343-5ce289a4416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_norm = [whisper_norm(x) for x in predictions]\n",
    "references_norm = [whisper_norm(x) for x in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3329428-deee-480f-9dee-e8174f42d02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11804961505560307"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predictions_norm, references=references_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53cbab69-30ed-4788-be0d-037130fef0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 0.11804961505560307,\n",
       " 'sub': 0.08297690333618478,\n",
       " 'del': 0.013686911890504704,\n",
       " 'ins': 0.0213857998289136}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_string_edit_metrics(predictions=predictions_norm, references=references_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989daba-0e9b-4fb3-b31e-de58bc31e603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
