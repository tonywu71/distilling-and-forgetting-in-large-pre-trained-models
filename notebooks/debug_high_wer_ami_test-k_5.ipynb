{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37324580-06a0-4be8-8194-70b8f85523c3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb50902-acec-4fe8-9681-d944478c0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba60d42-4585-4578-b142-c703099bd091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b422c568-7362-4361-8052-1b78696a1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.models.whisper import (WhisperTokenizer,\n",
    "                                         WhisperTokenizerFast,\n",
    "                                         WhisperFeatureExtractor,\n",
    "                                         WhisperForConditionalGeneration)\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "from dataloader.dataset_loader import gen_from_dataset\n",
    "from dataloader.dataset_for_evaluation.ami_test import AMITestSet\n",
    "from evaluation.string_edit_metrics import get_string_edit_metrics\n",
    "\n",
    "device = torch.device('mps')\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fcde89-6579-4200-bb8c-f0d0f618971a",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb40d39-119f-4c6a-b960-99dc206d6350",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44a8a39-776d-4177-ae70-33d876edefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name_or_path = \"openai/whisper-tiny\"\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(pretrained_model_name_or_path)\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(pretrained_model_name_or_path)\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(pretrained_model_name_or_path, language=\"english\", task=\"transcribe\")\n",
    "\n",
    "\n",
    "model.config.forced_decoder_ids = tokenizer.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")  # type: ignore\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "whisper_norm = tokenizer._normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482c627-cd0a-41ba-8e61-96bb22b02956",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2bcf1c7-5715-4c7e-8537-4dd0c06233e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: `CACHE_DIR_AMI` environment variable not set. Using default cache directory.\n"
     ]
    }
   ],
   "source": [
    "ds_group = AMITestSet(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af0dc52-2982-4376-ba18-6baf48666b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.iterable_dataset.IterableDataset at 0x2a1e35600>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds_group.str2dataset[\"ami\"]\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514824b-98c9-407e-a4ff-e800c3aaba75",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ed08a2-7488-4eda-858e-b72410c214ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_asr = pipeline(task=\"automatic-speech-recognition\",\n",
    "                       model=model,\n",
    "                       tokenizer=tokenizer,\n",
    "                       feature_extractor=feature_extractor,  # type: ignore\n",
    "                       device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157d5ba-883a-4ed9-9384-695eaeda6ecb",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c4788-c27f-47ee-9acc-3d65d519fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "n_samples = 200\n",
    "\n",
    "# Create placeholders for the predictions and references:\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for out in tqdm(whisper_asr(gen_from_dataset(ds),\n",
    "                            batch_size=16,\n",
    "                            generate_kwargs={\"num_beams\": 5}),\n",
    "                total=n_samples):\n",
    "    ref = whisper_norm(out[\"reference\"][0])\n",
    "    pred = whisper_norm(out[\"text\"])\n",
    "\n",
    "    if not ref.strip():\n",
    "        continue  # skip empty references to avoid error in WER computation\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    references.append(ref)\n",
    "    \n",
    "    count += 1\n",
    "    if count >= n_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3ab6f-d53d-4409-8065-2258b7d56ca9",
   "metadata": {},
   "source": [
    "## Compute string edit metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3329428-deee-480f-9dee-e8174f42d02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3610567514677103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53cbab69-30ed-4788-be0d-037130fef0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 1.3610567514677103,\n",
       " 'sub': 0.15166340508806261,\n",
       " 'del': 0.07925636007827788,\n",
       " 'ins': 1.13013698630137}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_string_edit_metrics(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e5607-d258-4933-ac43-a99df2315ace",
   "metadata": {},
   "source": [
    "## Per-example analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30177442-baa5-4ce4-8e34-14b5b02206b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  18\n",
      "prediction:  thanks for watching\n",
      "reference:  yeah\n",
      "3.0\n",
      "\n",
      "idx:  57\n",
      "prediction:  i am sorry\n",
      "reference:  so\n",
      "3.0\n",
      "\n",
      "idx:  117\n",
      "prediction:  yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah\n",
      "reference:  yeah\n",
      "221.0\n",
      "\n",
      "idx:  152\n",
      "prediction:  haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha haha\n",
      "reference:  yeah\n",
      "444.0\n",
      "\n",
      "idx:  156\n",
      "prediction:  ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha ha\n",
      "reference:  yeah\n",
      "443.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, (prediction, reference) in enumerate(zip(predictions, references)):\n",
    "    wer = get_string_edit_metrics(predictions=[prediction], references=[reference])[\"wer\"]\n",
    "    if wer > 2:\n",
    "        print(\"idx: \", idx)\n",
    "        print(\"prediction: \", prediction)\n",
    "        print(\"reference: \", reference)\n",
    "        print(wer)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819bd092-a031-4615-a33a-4f6d2523a08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
