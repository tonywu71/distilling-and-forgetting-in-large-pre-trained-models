{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb638b37-c3ba-4c60-b618-d7c875a799f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696bd80d-1a91-47ff-8629-632533796683",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed110f5-4077-4816-b73f-0970d2543b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdda7eb-200b-4a2d-931c-8f0d25041d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.models.whisper import (WhisperTokenizer,\n",
    "                                         WhisperTokenizerFast,\n",
    "                                         WhisperFeatureExtractor,\n",
    "                                         WhisperForConditionalGeneration)\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "from dataloader.collator import DataCollatorSpeechSeq2SeqWithPadding\n",
    "from dataloader.preprocessing_train.preprocessing import prepare_dataset_fct\n",
    "from evaluation.eval_dataset_name_to_dataset_group import EVAL_DATASET_NAME_TO_DATASET_GROUP\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "elif torch.backends.mps.is_available():  # for Apple Silicon\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef80ece-17b5-433e-8af3-af2bb8dd580b",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824d6e40-8a8f-4289-b2ce-85e161670ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name_or_path = \"openai/whisper-tiny\"\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(pretrained_model_name_or_path)\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(pretrained_model_name_or_path)\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(pretrained_model_name_or_path, language=\"english\", task=\"transcribe\")\n",
    "\n",
    "model.generate = partial(model.generate, language=\"english\", task=\"transcribe\",\n",
    "                         max_length=255, use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd2af4-0693-41a1-9ae2-01c6fa20a848",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426134a2-998e-4755-850f-3025fffc3110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: `CACHE_DIR_LIBRISPEECH` environment variable not set. Using default cache directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"librispeech_dummy\"\n",
    "# dataset_name = \"ami\"\n",
    "\n",
    "ds = EVAL_DATASET_NAME_TO_DATASET_GROUP[dataset_name]()[dataset_name]\n",
    "\n",
    "if dataset_name == \"ami\":\n",
    "    ds = ds.select(list(range(32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b253aad8-4eb5-4c2b-9223-c0b21a8cffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b/cache-59ee67852172721a_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset = partial(prepare_dataset_fct, tokenizer=tokenizer, feature_extractor=feature_extractor)\n",
    "ds = ds.map(prepare_dataset, num_proc=4).with_format(\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31d057-2496-43dd-a7e3-49fb1fd2b8f1",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623d7bbb-0262-4724-91fc-4c24239ac8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ds[0]\n",
    "\n",
    "x[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07c4cd8-4da3-4012-ab82-862190b279e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.',\n",
       " ' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.',\n",
       " ' Mr. Quilter is the apostle of the Middle Classes and we are glad to welcome his gospel.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(x[\"input_features\"][None, ...], num_beams=3, num_return_sequences=3)\n",
    "\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28ecbc3-86ee-47f4-885c-c688ed6a0159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Mr. Krilder is the Apostle of the Middle Classes, and we are glad to welcome his gospel.',\n",
       " ' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.',\n",
       " ' Mister Cilter is the apostle of the middle classes and we are glad to welcome his gospel.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(x[\"input_features\"][None, ...], do_sample=True, num_return_sequences=3)\n",
    "\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b97b25a-ed77-4fa3-b425-c8b03b514c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Mr. Kylder is the apostle of the Middle Classes, and we are glad to welcome his gospel.',\n",
       " ' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.',\n",
       " ' Mr. Quilter is the apostle of the middle classes and we are gladly to welcome his gospel.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(x[\"input_features\"][None, ...], do_sample=True, top_k=40, num_return_sequences=3)\n",
    "\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7575bca0-79fa-4f06-a70f-fb05aa427abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Mr. Kfilter is the apostle of the Middle Classes and we are glad to welcome his gospel.',\n",
       " ' Mr. Quilder is the apostle of the middle classes and we are glad to welcome his gospel.',\n",
       " ' Mr. Kilder, is the apostle of the middle classes and we are glad to welcome his gospel.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(x[\"input_features\"][None, ...], do_sample=True, top_k=40, temperature=0.7, num_return_sequences=3)\n",
    "\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0418903e-3b22-48c9-ae29-c8b0e7f5cb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Mr. Kwillter is the apostle of the middle classes and we are glad to welcome his Gospel.',\n",
       " ' Mr. Quilter is the apostle of the Middle classes and we are glad to welcome his gospel.',\n",
       " ' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(x[\"input_features\"][None, ...], do_sample=True, top_p=0.92, num_return_sequences=3)\n",
    "\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f12d47-d754-45d7-aee2-8c93a2e458c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
