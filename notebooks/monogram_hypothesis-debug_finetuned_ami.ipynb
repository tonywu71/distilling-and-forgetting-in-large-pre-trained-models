{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13fede6-b0a8-4049-a94e-fc2b1ee0bb45",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea6c58e-56e1-4a46-9872-1fb46b8f40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742e2c3f-9dfd-459b-9920-19587dec1690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad746412-a963-4e47-937b-6f942e654115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trainer.prompting import get_labels_with_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b77ce-97f8-4f68-a9e6-95e077bf040d",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1717acf-685f-470d-8d13-fb50fb7cbc11",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572bf93b-4caf-4261-9663-1f1e0f8609b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dirpath = \"checkpoints/tiny-finetuned_on_ami/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de81561-1b45-4462-b895-3f28e6e45090",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(checkpoint_dirpath)\n",
    "processor = WhisperProcessor.from_pretrained(checkpoint_dirpath)\n",
    "\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")  # type: ignore\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "normalizer = processor.tokenizer._normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df4261-5f36-41be-91db-15ff18077e3d",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8faee5fd-dac4-4a66-b74e-902d8bf1498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"edinburghcstr/ami\",\n",
    "                  name=\"ihm\",\n",
    "                  split=\"train\",\n",
    "                  streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49f4c27-bdf8-46fd-8c7b-34013c6a153a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meeting_id': 'EN2001a',\n",
       " 'audio_id': 'AMI_EN2001a_H04_MEO069_0145515_0146152',\n",
       " 'text': \"YEAH IT'LL IT'LL PLAY THEM IN SOME ORDER IN WHICH THEY WERE SET BECAUSE OTHERWISE IT'S GONNA BE MORE ENTERTAINING\",\n",
       " 'audio': {'path': 'EN2001a/train_ami_en2001a_h04_meo069_0145515_0146152.wav',\n",
       "  'array': array([ 0.00000000e+00,  0.00000000e+00,  6.10351562e-05, ...,\n",
       "         -6.10351562e-05, -6.10351562e-05, -3.05175781e-05]),\n",
       "  'sampling_rate': 16000},\n",
       " 'begin_time': 1455.15,\n",
       " 'end_time': 1461.52,\n",
       " 'microphone_id': 'H04',\n",
       " 'speaker_id': 'MEO069'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_iter = iter(ds)\n",
    "n_skip = 3\n",
    "\n",
    "for _ in range(n_skip):\n",
    "    next(ds_iter)\n",
    "\n",
    "x = next(ds_iter)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e0e02-188b-4144-8402-4d9087301cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('yeah it will it will play them in some order in which they were set because otherwise it is going to be more entertaining',\n",
       " torch.Size([1, 80, 3000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = normalizer(x[\"text\"])  # normalize label\n",
    "input_features = processor(x[\"audio\"][\"array\"], sampling_rate=x[\"audio\"][\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "\n",
    "label, input_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2028e91-ac9c-4ad5-ab98-8baa38e39b77",
   "metadata": {},
   "source": [
    "## ðŸ†• Change a few words to see if the model turned to a unigram predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da957a1d-0a12-46a3-9dba-1a2450b5ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'yes it will in some order in which they were set because otherwise it is going to be more entertaining'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8453ea82-7066-4480-9ebf-e5a95a7eb71c",
   "metadata": {},
   "source": [
    "## Tokenize the labels for teacher-forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8a8783-4982-47e3-acbc-5dc9da79ca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2346,   309,   486,   294,   512,  1668,   294,   597,   220, 13162,\n",
       "           645,   992,   570,  5911,   309,   307,   516,   220,  1353,   312,\n",
       "           544, 20402]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_label = torch.LongTensor(processor.tokenizer(label, add_special_tokens=False).input_ids)\n",
    "\n",
    "# Add batch dim:\n",
    "tokenized_labels = tokenized_label[None, :]\n",
    "\n",
    "tokenized_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0270d-680b-4f59-a4d3-9e0045a5589d",
   "metadata": {},
   "source": [
    "## Add prompts to teacher-forced labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5daf06e2-d737-4c6f-9104-767436a66fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 50259), (2, 50359), (3, 50363)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.get_decoder_prompt_ids(language=None, task=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6bc79db-09f7-4863-a746-19e073081a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363,  2346,   309,   486,   294,   512,  1668,\n",
       "           294,   597,   220, 13162,   645,   992,   570,  5911,   309,   307,\n",
       "           516,   220,  1353,   312,   544, 20402, 50257]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_with_prompt, n_prefix_tokens_labels, n_suffix_tokens_labels = get_labels_with_prompt(\n",
    "    labels=tokenized_labels, language=\"english\", task=\"transcribe\", tokenizer=processor.tokenizer)\n",
    "\n",
    "labels_with_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cc4e601-43f2-475c-8b49-1edee12b6ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|en|><|transcribe|><|notimestamps|>yes it will in some order in which they were set because otherwise it is going to be more entertaining<|endoftext|>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.batch_decode(labels_with_prompt, skip_special_tokens=False, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3392a-997b-49c0-9992-bfd4d9c7919f",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c645ff-cd04-48d5-a798-edc403647867",
   "metadata": {},
   "source": [
    "## Teacher-forced from ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "963f154b-d384-4943-83b7-ae58c767f32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|en|><|transcribe|><|notimestamps|>yes it will in some order in which they were set because otherwise it is going to be more entertaining<|endoftext|>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check (`pred_gen_str` won't be used here):\n",
    "labels_with_prompt_ids = processor.tokenizer.batch_decode(labels_with_prompt, skip_special_tokens=False, normalize=False)\n",
    "labels_with_prompt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6f8a7c6-e9ef-4144-91ae-1f192e7d170a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50359, 50363,  1338,   309,   486,   862,   862,  1668,   294,\n",
       "           597,   220, 13162,   645,   992,  3082,  5911,   309,   307,   516,\n",
       "           220,  1353,   312,   544, 20402, 50257, 50257]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.forward(input_features=input_features,\n",
    "                       decoder_input_ids=labels_with_prompt)\n",
    "logits = output.logits\n",
    "pred_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a91311f3-16de-4da3-a7d7-838987056f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|transcribe|><|notimestamps|> yeah it will play play order in which they were set cause otherwise it is going to be more entertaining<|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=False, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4915a-1f7f-4059-bef3-705c585b8048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
