{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13fede6-b0a8-4049-a94e-fc2b1ee0bb45",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea6c58e-56e1-4a46-9872-1fb46b8f40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742e2c3f-9dfd-459b-9920-19587dec1690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad746412-a963-4e47-937b-6f942e654115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import WhisperTokenizerFast, WhisperFeatureExtractor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dataloader.collator import DataCollatorSpeechSeq2SeqWithPadding\n",
    "from dataloader.preprocessing_train.preprocessing import prepare_dataset_fct, preprocess_dataset\n",
    "from dataloader.collator import DataCollatorSpeechSeq2SeqWithPadding\n",
    "from trainer.prompting import get_labels_with_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b77ce-97f8-4f68-a9e6-95e077bf040d",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1717acf-685f-470d-8d13-fb50fb7cbc11",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de81561-1b45-4462-b895-3f28e6e45090",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "tokenizer = WhisperTokenizerFast.from_pretrained(\"openai/whisper-tiny\", language=\"english\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")\n",
    "\n",
    "model.config.forced_decoder_ids = tokenizer.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")\n",
    "\n",
    "normalizer = tokenizer._normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df4261-5f36-41be-91db-15ff18077e3d",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8faee5fd-dac4-4a66-b74e-902d8bf1498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "# load dummy dataset and read audio files\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd54cf-3bf1-4e5d-9121-9ab92c3f6416",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f22e829e-90dc-4ab2-93f7-e7962c564e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b/cache-03b95896c8a778b5_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset = partial(prepare_dataset_fct,\n",
    "                          tokenizer=tokenizer,\n",
    "                          feature_extractor=feature_extractor)\n",
    "ds = ds.map(prepare_dataset, num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e341e74-599e-4b32-9a55-06c80f746e7c",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6aa40be-28c8-4b32-89c5-461ffcbcd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(tokenizer=tokenizer,\n",
    "                                                     feature_extractor=feature_extractor,\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     replace_padded_with_loss_mask_for_labels=False,\n",
    "                                                     discard_first_bos_token=True)\n",
    "\n",
    "dataloader = DataLoader(ds,\n",
    "                        batch_size=2,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa63c7-8372-4bf6-b077-52f7a9887e2f",
   "metadata": {},
   "source": [
    "## EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf90134-eaf0-4209-a14c-b6da5bea6337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_features', 'labels', 'attention_mask'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(dataloader))\n",
    "\n",
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d372ac5c-c1cd-4b8d-b560-3568c1b86a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 39])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c02878-3259-455a-9e38-02f693a19983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363,    44,  2343,  5568,  7246,  4620,  5568,\n",
       "          6205,  5663,  5372, 28067,  2634, 11944,  5663, 32394,    35,  2634,\n",
       "         12855, 19678,  2358,  8093, 15813, 22515, 16225,  6112,  8232,   343,\n",
       "          3158,    34, 23344, 45470,   460,  4367,    47,  3158, 50257],\n",
       "        [50258, 50259, 50359, 50363,    45,  2483,  6205,   376,  2343,  5568,\n",
       "          7246,  4620,  5568,     6,    50, 15372, 24499,   441, 12268, 30219,\n",
       "         14497,  3017,  3578,  1770, 45470,  5904,  5568, 50257, 50257, 50257,\n",
       "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb660a6-46bf-44ef-8af6-83c9c9ddca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**x)\n",
    "\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7c83af-99e9-4f1e-a5b0-3b618a1ae868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd39b88-d0c4-4869-98d1-2bb370ac52fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-24.9806, -26.2099, -20.7334,  ..., -22.3784, -20.9287, -21.0396],\n",
       "         [-31.5374, -35.2910, -30.8864,  ..., -32.0047, -32.2249, -29.0637],\n",
       "         [-28.3196, -31.2453, -27.7084,  ..., -28.6791, -28.9073, -26.4736],\n",
       "         ...,\n",
       "         [-11.4710, -10.5310, -11.0410,  ..., -13.1237, -13.4056, -13.2360],\n",
       "         [ -7.2245,  -7.4540, -12.2601,  ..., -11.0964, -11.6803, -12.4698],\n",
       "         [ -2.3228,  -6.5579, -10.2790,  ..., -11.7745, -11.6631, -13.3594]],\n",
       "\n",
       "        [[-22.5718, -23.0225, -18.2253,  ..., -20.4687, -18.9090, -19.0197],\n",
       "         [-26.7977, -31.3636, -29.3994,  ..., -28.4255, -28.9399, -26.4021],\n",
       "         [-29.9452, -32.8312, -29.4124,  ..., -30.4019, -30.6734, -28.2721],\n",
       "         ...,\n",
       "         [ -6.9904,  -4.5795,  -7.5210,  ..., -10.2067, -10.2836, -13.1559],\n",
       "         [ -7.1982,  -4.9151,  -7.4744,  ...,  -9.8854, -10.0806, -13.3250],\n",
       "         [ -6.9058,  -4.6428,  -7.4882,  ..., -10.0364, -10.2691, -13.5632]]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_all = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "log_prob_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b03b67c1-33d1-4ccb-8e97-1113f6d785a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 39, 51865])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26400473-9d60-4c67-84a6-a49a758a196d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob = log_prob_all.take_along_dim(x.labels[..., None], dim=-1).squeeze().sum(dim=-1)\n",
    "log_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46683618-de8c-4df0-b8cc-3559b7ea96d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-114.8479, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood = torch.mean(log_prob)\n",
    "log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ac6af0-4fde-4b23-b691-111a499bfc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_log_likelihood = torch.autograd.grad(log_likelihood, model.parameters())\n",
    "len(grad_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92bf14ce-b7f2-4d6c-ace7-564cd14cfce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.encoder.conv1.weight torch.Size([384, 80, 3]) torch.Size([384, 80, 3])\n",
      "model.encoder.conv1.bias torch.Size([384]) torch.Size([384])\n",
      "model.encoder.conv2.weight torch.Size([384, 384, 3]) torch.Size([384, 384, 3])\n",
      "model.encoder.conv2.bias torch.Size([384]) torch.Size([384])\n",
      "model.encoder.embed_positions.weight torch.Size([1500, 384]) torch.Size([1500, 384])\n",
      "model.encoder.layers.0.self_attn.k_proj.weight torch.Size([384, 384]) torch.Size([384, 384])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for (name, param), grad_param in zip(model.named_parameters(), grad_log_likelihood):\n",
    "    if count > 5:\n",
    "        break\n",
    "    print(name, param.shape, grad_param.shape)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f75ec-c69e-49f8-a193-a8d35a54c6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
