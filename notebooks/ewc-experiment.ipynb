{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13fede6-b0a8-4049-a94e-fc2b1ee0bb45",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea6c58e-56e1-4a46-9872-1fb46b8f40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742e2c3f-9dfd-459b-9920-19587dec1690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad746412-a963-4e47-937b-6f942e654115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trainer.prompting import get_labels_with_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b77ce-97f8-4f68-a9e6-95e077bf040d",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1717acf-685f-470d-8d13-fb50fb7cbc11",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de81561-1b45-4462-b895-3f28e6e45090",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")  # type: ignore\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "normalizer = processor.tokenizer._normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df4261-5f36-41be-91db-15ff18077e3d",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8faee5fd-dac4-4a66-b74e-902d8bf1498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "# load dummy dataset and read audio files\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49f4c27-bdf8-46fd-8c7b-34013c6a153a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/Users/Tony/.cache/huggingface/datasets/downloads/extracted/ebb1d3f740add5af71e53b628d8c9c55e64fc2ff14a6ff31de01228adc704d35/dev_clean/1272/128104/1272-128104-0000.flac',\n",
       " 'audio': {'path': '/Users/Tony/.cache/huggingface/datasets/downloads/extracted/ebb1d3f740add5af71e53b628d8c9c55e64fc2ff14a6ff31de01228adc704d35/dev_clean/1272/128104/1272-128104-0000.flac',\n",
       "  'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
       "         0.0010376 ]),\n",
       "  'sampling_rate': 16000},\n",
       " 'text': 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL',\n",
       " 'speaker_id': 1272,\n",
       " 'chapter_id': 128104,\n",
       " 'id': '1272-128104-0000'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(ds))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37e0e02-188b-4144-8402-4d9087301cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mister quilter is the apostle of the middle classes and we are glad to welcome his gospel',\n",
       " torch.Size([1, 80, 3000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = normalizer(x[\"text\"])  # normalize label\n",
    "input_features = processor(x[\"audio\"][\"array\"], sampling_rate=x[\"audio\"][\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "\n",
    "label, input_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8453ea82-7066-4480-9ebf-e5a95a7eb71c",
   "metadata": {},
   "source": [
    "## Tokenize the labels for teacher-forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8a8783-4982-47e3-acbc-5dc9da79ca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   76,  1964, 31619,   391,   307,   220,  3322, 50244,   295,   220,\n",
       "          3322,  2808,  5359,   293,   321,   366,  5404,   220,  1353,  2928,\n",
       "           702, 14943]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_label = torch.LongTensor(processor.tokenizer(label, add_special_tokens=False).input_ids)\n",
    "\n",
    "# Add batch dim:\n",
    "tokenized_labels = tokenized_label[None, :]\n",
    "\n",
    "tokenized_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0270d-680b-4f59-a4d3-9e0045a5589d",
   "metadata": {},
   "source": [
    "## Add prompts to teacher-forced labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9140b3-5d0b-4469-a5bd-cbc977672ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363,    76,  1964, 31619,   391,   307,   220,\n",
       "          3322, 50244,   295,   220,  3322,  2808,  5359,   293,   321,   366,\n",
       "          5404,   220,  1353,  2928,   702, 14943, 50257]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_with_prompt, n_prefix_tokens_labels, n_suffix_tokens_labels = get_labels_with_prompt(\n",
    "    labels=tokenized_labels, language=\"english\", task=\"transcribe\", tokenizer=processor.tokenizer)\n",
    "\n",
    "labels_with_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cc4e601-43f2-475c-8b49-1edee12b6ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|startoftranscript|><|en|><|transcribe|><|notimestamps|>mister quilter is the apostle of the middle classes and we are glad to welcome his gospel<|endoftext|>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.batch_decode(labels_with_prompt, skip_special_tokens=False, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c25767-1089-4a21-88fc-4bcea3b437c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50359, 50363,    76,  1964, 31619,   391,   307,   220,\n",
       "          3322, 50244,   295,   220,  3322,  2808,  5359,   293,   321,   366,\n",
       "          5404,   220,  1353,  2928,   702, 14943, 50257]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_with_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "240cea9f-354a-42fd-a0b8-39ad32787193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50258, 50259, 50359, 50363]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.prefix_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "898f0ed1-fcd6-439b-871d-da7311263fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.whisper.tokenization_whisper import LANGUAGES, TO_LANGUAGE_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "326aee2c-fb97-41da-8868-ba238146e556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e8028c1-c0a1-43ff-9feb-12d029ce507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_token(language: str):\n",
    "    idx_shift = 50258\n",
    "    langs = tuple(LANGUAGES.keys())\n",
    "    \n",
    "    language = language.lower()\n",
    "    if language in TO_LANGUAGE_CODE:\n",
    "        language_id = TO_LANGUAGE_CODE[language]\n",
    "    elif language in TO_LANGUAGE_CODE.values():\n",
    "        language_id = language\n",
    "    else:\n",
    "        is_language_code = len(language) == 2\n",
    "        raise ValueError(\n",
    "            f\"Unsupported language: {language}. Language should be one of:\"\n",
    "            f\" {list(TO_LANGUAGE_CODE.values()) if is_language_code else list(TO_LANGUAGE_CODE.keys())}.\"\n",
    "        )\n",
    "    \n",
    "    return idx_shift + 1 + langs.index(language_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72b5c14d-ade9-4b9c-b58c-67dd2a0950bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50259"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_language_token(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08b030b2-cab8-4463-8525-8cee491c46c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50258"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.all_special_ids[-106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9ba6f96-c380-4fd2-90a3-f27f2216199a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 50259), (2, 50359), (3, 50363)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.get_decoder_prompt_ids(language=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3392a-997b-49c0-9992-bfd4d9c7919f",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c645ff-cd04-48d5-a798-edc403647867",
   "metadata": {},
   "source": [
    "## Teacher-forced from greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ca435-8fab-4200-966b-bfd38b0cc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate with greedy search - vanilla\n",
    "pred_gen_raw = model.generate(inputs=input_features)\n",
    "pred_gen_str = processor.tokenizer.batch_decode(pred_gen_raw, skip_special_tokens=True, normalize=False)\n",
    "pred_gen = torch.LongTensor(processor.tokenizer.encode(pred_gen_str[0], add_special_tokens=False))[None, :]\n",
    "\n",
    "pred_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eed06f-b3c7-453e-a1b3-8613a97f6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.batch_decode(pred_gen, skip_special_tokens=False, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eeb2b7-298c-443f-8a06-c68c9377ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen_with_prompts, n_prefix_tokens_labels, n_suffix_tokens_labels = get_labels_with_prompt(\n",
    "    labels=pred_gen, language=\"french\", task=\"transcribe\", tokenizer=processor.tokenizer)\n",
    "\n",
    "pred_gen_with_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f154b-d384-4943-83b7-ae58c767f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check (`pred_gen_str` won't be used here):\n",
    "pred_gen_str = processor.tokenizer.batch_decode(pred_gen_with_prompts, skip_special_tokens=False, normalize=False)\n",
    "pred_gen_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8a7c6-e9ef-4144-91ae-1f192e7d170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(input_features=input_features,\n",
    "                       decoder_input_ids=pred_gen_with_prompts)\n",
    "logits = output.logits\n",
    "pred_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91311f3-16de-4da3-a7d7-838987056f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=False, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26a0d5-a711-4f7a-a146-57641bd1c0a8",
   "metadata": {},
   "source": [
    "**Interesting:** The model recognized that the source is English as it outputed `<|en|>`. Yet, it got teacher-forced to predict `<|fr|>`. At that moment, the model decided the task of interest was `<|translate|>` which makes sense. However, the rest of the prediction is not a translation of the original sentence because of teacher-forcing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4915a-1f7f-4059-bef3-705c585b8048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
