{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63fc2f27-fe9e-4161-9b89-5ed66093dbbf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd20bdf-6576-490c-b9f9-304b50ebdf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea892cd0-272f-4917-883f-40f7e63bff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tony/Other Docs/distilling-and-forgetting-in-large-pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8531dd9b-d99f-4e3d-be5b-0714ce884202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d7b8b-268a-406d-be9f-caa797e0b45a",
   "metadata": {},
   "source": [
    "## Load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5cd121-e2d9-43a7-9c56-5cfbdd843772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model.config.forced_decoder_ids = None\n",
    "\n",
    "normalizer = processor.tokenizer._normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b485908-4e1a-4c98-9f87-1ea6b32db5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/Users/Tony/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "# load dummy dataset and read audio files\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b27f9-7e1d-45e3-b133-cdfb694f4141",
   "metadata": {},
   "source": [
    "## Create a 2-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2722c1e4-7de1-44f9-91ee-4bb68fbf9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_0 = ds[0][\"audio\"]\n",
    "label_0 = normalizer(ds[0][\"text\"])  # normalize label\n",
    "input_features_0 = processor(sample_0[\"array\"], sampling_rate=sample_0[\"sampling_rate\"], return_tensors=\"pt\").input_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23cfda7-8ac6-4879-9e90-b414c3c2458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = ds[1][\"audio\"]\n",
    "label_1 = normalizer(ds[1][\"text\"])  # normalize label\n",
    "input_features_1 = processor(sample_1[\"array\"], sampling_rate=sample_1[\"sampling_rate\"], return_tensors=\"pt\").input_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75df78f-2297-411f-b1c1-0429a186c0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mister quilter is the apostle of the middle classes and we are glad to welcome his gospel',\n",
       " 'nor is mister quilter is manner less interesting than his matter')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_0, label_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82ed70-7a5d-45ce-8a61-ca8b01e53787",
   "metadata": {},
   "source": [
    "### Batch `input_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0bfe62f-64c0-46cb-aef0-6c58655371b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert input_features_0.shape == input_features_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e1a13a-a551-45c0-bde8-3d0aad2f30cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 3000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = torch.concat([input_features_0, input_features_1], axis=0)\n",
    "input_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca849ab-64b8-4e57-a9cb-39f2604c486a",
   "metadata": {},
   "source": [
    "### Batch `tokenized_label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f548f7eb-ee33-4ef3-b47a-152160de7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to use `torch.LongTensor` because default dtype is float:\n",
    "tokenized_label_0 = torch.LongTensor(processor.tokenizer(label_0, add_special_tokens=True).input_ids)\n",
    "tokenized_label_1 = torch.LongTensor(processor.tokenizer(label_1, add_special_tokens=True).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f3fec3-391b-4328-ae40-2192073b167e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23]), torch.Size([17]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_label_0.shape, tokenized_label_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8714073b-bd46-4449-b1ed-60d8afd3ad77",
   "metadata": {},
   "source": [
    "⚠️ The `input_features` share the same shape but this is not true for the tokenized sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "546c7d08-4b13-4aa5-8737-af09e1fec4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = [{\"input_ids\": tokenized_label_0}, {\"input_ids\": tokenized_label_1}]\n",
    "labels_batch = processor.tokenizer.pad(label_features, return_tensors=\"pt\")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7374d38c-32de-4fbc-b90c-2818563593ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50257, 50362,    76,  1694,   627,   346,   353,   318,   262, 46329,\n",
       "           286,   262,  3504,  6097,   290,   356,   389,  9675,   284,  7062,\n",
       "           465, 21443, 50256],\n",
       "        [50257, 50362, 13099,   318,   285,  1694,   627,   346,   353,   318,\n",
       "          5642,  1342,  3499,   621,   465,  2300, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70b3405-7d01-41c6-afed-30f3d903d391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 23]), torch.Size([2, 23]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_batch[\"input_ids\"].shape, labels_batch[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed4bd9-a502-4319-b089-0c32235358f8",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec1c45-dde9-4445-abc7-8d26a35a81ac",
   "metadata": {},
   "source": [
    "### Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ac62f0c-4ff5-4b6a-b9a5-1c00afa23bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 80, 3000]), torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.shape, input_features.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "014b0327-47dd-430c-95c3-b1f64d2d5003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 23]), torch.int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume the teacher is a perfect model:\n",
    "teacher_sequences = labels_batch[\"input_ids\"]\n",
    "teacher_sequences.shape, teacher_sequences.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6acef8de-2112-4307-9459-ed498b6d5dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 23])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_batch[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9021506-fddc-4daa-96e8-eb95e53153f2",
   "metadata": {},
   "source": [
    "### Predict without attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f5d4894-af32-4412-823d-057464def01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1817, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_no_mask = model.forward(input_features=input_features,\n",
    "                               decoder_input_ids=teacher_sequences[:, :-1],\n",
    "                               labels=teacher_sequences[:, 1:])\n",
    "output_no_mask.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9d0e0-7315-4da8-8ccc-ffa060ef6b31",
   "metadata": {},
   "source": [
    "### Predict with attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a4b639e-0604-49e9-b1a5-f37af890c05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1591, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_with_mask = model.forward(input_features=input_features,\n",
    "                                 decoder_input_ids=teacher_sequences[:, :-1],\n",
    "                                 labels=teacher_sequences[:, 1:],\n",
    "                                 decoder_attention_mask=labels_batch[\"attention_mask\"][:, :-1])\n",
    "output_with_mask.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6ef4e-2b8e-46f2-8d42-b03e9e38031c",
   "metadata": {},
   "source": [
    "### Output comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c94e00-8107-4d2e-a292-dec577f00253",
   "metadata": {},
   "source": [
    "Note how the 2 losses are different. We can then deduce that the logits are also different but let's display a few values for the 2nd example to confirm our assumption (the 1st example has no padded tokens because it is the longest of the two)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfd06616-c588-4639-a93d-e9b65b6def7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3879,  4.8095,  3.3221,  ...,  4.8180,  4.0716,  3.8354],\n",
       "        [ 3.6629,  2.7278,  0.0581,  ...,  2.5407,  2.9286,  1.1074],\n",
       "        [13.8955, 14.5302,  8.8014,  ..., 10.1489,  9.2304,  8.5802],\n",
       "        ...,\n",
       "        [10.9755, 10.8193,  8.5395,  ...,  6.0354,  5.9234,  3.9300],\n",
       "        [10.9274, 11.0745,  9.0230,  ...,  6.5457,  6.4562,  4.4609],\n",
       "        [10.0324, 10.8805,  8.8594,  ...,  6.5510,  6.4207,  4.4512]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_no_mask.logits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46c134b3-41a2-4140-a778-0846ce88b5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3879,  4.8095,  3.3221,  ...,  4.8180,  4.0716,  3.8354],\n",
       "        [ 3.6629,  2.7278,  0.0581,  ...,  2.5407,  2.9286,  1.1074],\n",
       "        [13.8955, 14.5302,  8.8014,  ..., 10.1489,  9.2304,  8.5802],\n",
       "        ...,\n",
       "        [19.6800, 18.7776, 13.9299,  ..., 11.1630, 11.0890,  8.8313],\n",
       "        [19.2387, 18.4690, 13.6283,  ..., 11.0549, 10.9934,  8.7443],\n",
       "        [18.5419, 17.7504, 13.1372,  ..., 10.5019, 10.4164,  8.1769]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_with_mask.logits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf47e06-8bd3-4e50-b448-61753213cf41",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "- The first first rows ARE equal because our model uses a causal attention mechanism. Therefore, the attention doesn't have the chance to consider the pad tokens at the end of the sequence. Hence the similarity.\n",
    "- The last rows differ for the same reason. Although we could just set them to 0 (which is something we will do eventually), it is good practice to mask them properly. Moreover, we can save some computation time here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af008f85-babd-47b3-8919-86c27485c688",
   "metadata": {},
   "source": [
    "### Apply softmax to get the vocab probabilities per step and per example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95813cfc-2c4d-4a8b-a35d-5a7a8685fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-15.3003, -14.7483, -15.9119,  ..., -14.5757, -15.3342, -15.6124],\n",
       "         [-11.7886, -12.7940, -14.2199,  ..., -15.2796, -16.0519, -18.6459],\n",
       "         [-10.8017, -10.6024, -10.8728,  ..., -10.2841, -11.3689, -13.7109],\n",
       "         ...,\n",
       "         [-13.6878, -11.9338, -15.5179,  ..., -17.6529, -16.9946, -18.3999],\n",
       "         [-12.3648, -13.3746, -15.7683,  ..., -17.4096, -18.9184, -19.5019],\n",
       "         [ -3.2312,  -6.1660, -13.3379,  ..., -16.0522, -15.7055, -18.1209]],\n",
       "\n",
       "        [[-14.8043, -14.3827, -15.8701,  ..., -14.3742, -15.1206, -15.3568],\n",
       "         [-11.9963, -12.9314, -15.6011,  ..., -13.1185, -12.7306, -14.5518],\n",
       "         [ -8.8980,  -8.2633, -13.9921,  ..., -12.6446, -13.5631, -14.2132],\n",
       "         ...,\n",
       "         [ -5.7692,  -6.6717, -11.5194,  ..., -14.2862, -14.3603, -16.6180],\n",
       "         [ -6.1038,  -6.8735, -11.7142,  ..., -14.2876, -14.3490, -16.5981],\n",
       "         [ -6.2201,  -7.0116, -11.6248,  ..., -14.2601, -14.3456, -16.5851]]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_log_prob = torch.nn.functional.log_softmax(output_with_mask.logits, dim=-1)  # (batch_size, n_tokens-1, vocab_size)\n",
    "output_log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2502ddc-40b8-4b04-8345-2d071f933756",
   "metadata": {},
   "source": [
    "### Set the values associated to the pad tokens to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893264bf-42da-494c-9ea7-a0f72aa65efd",
   "metadata": {},
   "source": [
    "Because we will sum the log-probabilities to make use of the product rule in the log space, a sufficient method to ignore the padded values is to set them to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e99f045-0be1-452e-8417-7a994c3f2c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51864"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab = output_with_mask.logits.shape[-1]\n",
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a2428fd-4511-4429-a608-947027582b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 22, 51864])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat attention_mask for the n_vocab dimension:\n",
    "mask = labels_batch[\"attention_mask\"][:, :-1, None].expand(-1, -1, n_vocab)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf21cbdd-cb35-4839-8381-e8150ac556b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-15.3003, -14.7483, -15.9119,  ..., -14.5757, -15.3342, -15.6124],\n",
       "         [-11.7886, -12.7940, -14.2199,  ..., -15.2796, -16.0519, -18.6459],\n",
       "         [-10.8017, -10.6024, -10.8728,  ..., -10.2841, -11.3689, -13.7109],\n",
       "         ...,\n",
       "         [-13.6878, -11.9338, -15.5179,  ..., -17.6529, -16.9946, -18.3999],\n",
       "         [-12.3648, -13.3746, -15.7683,  ..., -17.4096, -18.9184, -19.5019],\n",
       "         [ -3.2312,  -6.1660, -13.3379,  ..., -16.0522, -15.7055, -18.1209]],\n",
       "\n",
       "        [[-14.8043, -14.3827, -15.8701,  ..., -14.3742, -15.1206, -15.3568],\n",
       "         [-11.9963, -12.9314, -15.6011,  ..., -13.1185, -12.7306, -14.5518],\n",
       "         [ -8.8980,  -8.2633, -13.9921,  ..., -12.6446, -13.5631, -14.2132],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_log_prob_masked = output_log_prob.masked_fill(mask.ne(1), 0)\n",
    "output_log_prob_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3e92fe1-d053-4e4f-94c7-28134716d606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.2312,  -6.1660, -13.3379,  ..., -16.0522, -15.7055, -18.1209],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Row 1 should be non-null and row 2 should be full of 0s:\n",
    "output_log_prob_masked[:, -1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8755516d-fb22-4620-8a72-786b39f11314",
   "metadata": {},
   "source": [
    "## Compute the log-probability of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3133193a-b875-494d-8b10-baf9b6553a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 22, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_t_hat_step_wise = output_log_prob_masked.take_along_dim(teacher_sequences[:, 1:, None], dim=-1)\n",
    "log_prob_t_hat_step_wise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0518b045-a7c4-4a8c-9b23-c866b3fa6351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-19.2571, -30.6052], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob_t_hat_step_wise.squeeze().sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0250b-91b3-463d-874a-e08777bbf42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
