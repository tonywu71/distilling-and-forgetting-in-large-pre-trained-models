{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37324580-06a0-4be8-8194-70b8f85523c3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb50902-acec-4fe8-9681-d944478c0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba60d42-4585-4578-b142-c703099bd091",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b422c568-7362-4361-8052-1b78696a1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import whisper\n",
    "import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from evaluation.eval_dataset_name_to_dataset_group import EVAL_DATASET_NAME_TO_DATASET_GROUP\n",
    "\n",
    "device = torch.device('mps')\n",
    "sns.set_theme(context=\"paper\", style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fcde89-6579-4200-bb8c-f0d0f618971a",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb40d39-119f-4c6a-b960-99dc206d6350",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830287c-2179-4c17-9489-e7951e4a1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"tiny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482c627-cd0a-41ba-8e61-96bb22b02956",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bcf1c7-5715-4c7e-8537-4dd0c06233e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ami_10h\"\n",
    "\n",
    "ds_group = EVAL_DATASET_NAME_TO_DATASET_GROUP[dataset_name]()\n",
    "\n",
    "if dataset_name == \"librispeech_dummy\":\n",
    "    ds = ds_group.str2dataset[\"librispeech_dummy\"]\n",
    "    ds = ds.map(lambda x: {\"text\": x.lower()}, input_columns=[\"text\"])\n",
    "elif dataset_name in [\"ami\", \"ami_10h\"]:\n",
    "    ds = ds_group.str2dataset[\"ami\"]\n",
    "    ds = ds.map(lambda x: {\"text\": x.lower()}, input_columns=[\"text\"])\n",
    "else:\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d42b4-3fd7-4763-a93b-f0368a0ab233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill `list_idx_hallucination` according to previous analysis:\n",
    "list_idx_hallucination = [38, 223, 227, 602, 789, 852, 1146]\n",
    "\n",
    "ds_hallucinations = ds.select(indices=list_idx_hallucination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da9cbc-d0c5-4c8c-85f4-3040247937fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "references = []\n",
    "list_audios = []\n",
    "\n",
    "for sample in tqdm(ds_hallucinations, total=ds_hallucinations.num_rows):\n",
    "    results.append(model.transcribe(sample[\"audio\"][\"array\"].astype(np.float32),\n",
    "                                    language=\"en\",\n",
    "                                    temperature=0.0,\n",
    "                                    word_timestamps=True))\n",
    "    references.append(sample[\"text\"].lower())\n",
    "    list_audios.append(dict(data=sample[\"audio\"][\"array\"], rate=sample[\"audio\"][\"sampling_rate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cd859-f8c4-4abf-b8da-b784129413c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio, result, ref in zip(list_audios, results, references):\n",
    "    # Load Audio player:\n",
    "    display(Audio(**audio))\n",
    "    \n",
    "    # Print the transcribed text and word timestamps\n",
    "    print(\"Reference: \", ref)\n",
    "    print(\"Prediction: \", result[\"text\"])\n",
    "    print()\n",
    "     \n",
    "    # Plot the token timestamps\n",
    "    timestamps = []\n",
    "    tokens = []\n",
    "    counter = 0\n",
    "    for segment in result[\"segments\"]:\n",
    "        for word in segment[\"words\"]:\n",
    "            timestamps.append(word[\"start\"])\n",
    "            timestamps.append(word[\"end\"])\n",
    "            tokens.append(str(counter) + word[\"word\"])\n",
    "            tokens.append(str(counter) + word[\"word\"])\n",
    "            counter += 1\n",
    "    plt.figure(figsize=(8, len(tokens)*0.1))\n",
    "    plt.plot(timestamps[::-1], tokens[::-1])\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Token\")\n",
    "    plt.title(\"Token Timestamps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991fe092-1d7b-4562-af12-e3eb06382334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
